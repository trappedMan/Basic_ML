{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "os.path.expanduser = lambda path: './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 60\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Model(Dropout rate 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training(Dropout rate 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.1964 - accuracy: 0.6194 - val_loss: 0.7336 - val_accuracy: 0.7558\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7406 - accuracy: 0.7520 - val_loss: 0.6155 - val_accuracy: 0.7909\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6476 - accuracy: 0.7793 - val_loss: 0.5576 - val_accuracy: 0.8116\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5926 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.8216\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5588 - accuracy: 0.8096 - val_loss: 0.5021 - val_accuracy: 0.8297\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5347 - accuracy: 0.8160 - val_loss: 0.4841 - val_accuracy: 0.8358\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5134 - accuracy: 0.8234 - val_loss: 0.4705 - val_accuracy: 0.8392\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4967 - accuracy: 0.8299 - val_loss: 0.4583 - val_accuracy: 0.8436\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4863 - accuracy: 0.8313 - val_loss: 0.4557 - val_accuracy: 0.8409\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4728 - accuracy: 0.8353 - val_loss: 0.4435 - val_accuracy: 0.8467\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4652 - accuracy: 0.8387 - val_loss: 0.4387 - val_accuracy: 0.8476\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4571 - accuracy: 0.8416 - val_loss: 0.4285 - val_accuracy: 0.8503\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4450 - accuracy: 0.8445 - val_loss: 0.4262 - val_accuracy: 0.8508\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4399 - accuracy: 0.8474 - val_loss: 0.4171 - val_accuracy: 0.8553\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4329 - accuracy: 0.8498 - val_loss: 0.4088 - val_accuracy: 0.8576\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4258 - accuracy: 0.8499 - val_loss: 0.4091 - val_accuracy: 0.8582\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4202 - accuracy: 0.8533 - val_loss: 0.4020 - val_accuracy: 0.8595\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4153 - accuracy: 0.8535 - val_loss: 0.3994 - val_accuracy: 0.8622\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4109 - accuracy: 0.8562 - val_loss: 0.3921 - val_accuracy: 0.8627\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4043 - accuracy: 0.8577 - val_loss: 0.3897 - val_accuracy: 0.8638\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3971 - accuracy: 0.8614 - val_loss: 0.3866 - val_accuracy: 0.8643\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3956 - accuracy: 0.8608 - val_loss: 0.3874 - val_accuracy: 0.8635\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3908 - accuracy: 0.8615 - val_loss: 0.3814 - val_accuracy: 0.8653\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3880 - accuracy: 0.8626 - val_loss: 0.3765 - val_accuracy: 0.8689\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3829 - accuracy: 0.8657 - val_loss: 0.3739 - val_accuracy: 0.8687\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3781 - accuracy: 0.8659 - val_loss: 0.3706 - val_accuracy: 0.8702\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3759 - accuracy: 0.8676 - val_loss: 0.3696 - val_accuracy: 0.8696\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3716 - accuracy: 0.8669 - val_loss: 0.3676 - val_accuracy: 0.8703\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3688 - accuracy: 0.8680 - val_loss: 0.3642 - val_accuracy: 0.8720\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3658 - accuracy: 0.8702 - val_loss: 0.3626 - val_accuracy: 0.8718\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3619 - accuracy: 0.8715 - val_loss: 0.3605 - val_accuracy: 0.8719\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3592 - accuracy: 0.8719 - val_loss: 0.3593 - val_accuracy: 0.8733\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3562 - accuracy: 0.8731 - val_loss: 0.3571 - val_accuracy: 0.8733\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3545 - accuracy: 0.8739 - val_loss: 0.3564 - val_accuracy: 0.8729\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3499 - accuracy: 0.8755 - val_loss: 0.3547 - val_accuracy: 0.8737\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3496 - accuracy: 0.8750 - val_loss: 0.3501 - val_accuracy: 0.8771\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3455 - accuracy: 0.8767 - val_loss: 0.3499 - val_accuracy: 0.8762\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3446 - accuracy: 0.8756 - val_loss: 0.3472 - val_accuracy: 0.8762\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3422 - accuracy: 0.8778 - val_loss: 0.3476 - val_accuracy: 0.8773\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3412 - accuracy: 0.8773 - val_loss: 0.3453 - val_accuracy: 0.8781\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3377 - accuracy: 0.8792 - val_loss: 0.3479 - val_accuracy: 0.8773\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3339 - accuracy: 0.8808 - val_loss: 0.3429 - val_accuracy: 0.8787\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3322 - accuracy: 0.8814 - val_loss: 0.3418 - val_accuracy: 0.8786\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3306 - accuracy: 0.8817 - val_loss: 0.3398 - val_accuracy: 0.8790\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3274 - accuracy: 0.8830 - val_loss: 0.3425 - val_accuracy: 0.8787\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3273 - accuracy: 0.8823 - val_loss: 0.3362 - val_accuracy: 0.8804\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3241 - accuracy: 0.8835 - val_loss: 0.3370 - val_accuracy: 0.8806\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3221 - accuracy: 0.8854 - val_loss: 0.3364 - val_accuracy: 0.8792\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3198 - accuracy: 0.8857 - val_loss: 0.3335 - val_accuracy: 0.8813\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3179 - accuracy: 0.8857 - val_loss: 0.3365 - val_accuracy: 0.8811\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3163 - accuracy: 0.8877 - val_loss: 0.3304 - val_accuracy: 0.8833\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3124 - accuracy: 0.8881 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3126 - accuracy: 0.8878 - val_loss: 0.3332 - val_accuracy: 0.8818\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3124 - accuracy: 0.8871 - val_loss: 0.3275 - val_accuracy: 0.8832\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3077 - accuracy: 0.8889 - val_loss: 0.3284 - val_accuracy: 0.8827\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3070 - accuracy: 0.8902 - val_loss: 0.3268 - val_accuracy: 0.8839\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3066 - accuracy: 0.8913 - val_loss: 0.3243 - val_accuracy: 0.8844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3031 - accuracy: 0.8911 - val_loss: 0.3236 - val_accuracy: 0.8848\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3019 - accuracy: 0.8924 - val_loss: 0.3236 - val_accuracy: 0.8855\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3002 - accuracy: 0.8929 - val_loss: 0.3224 - val_accuracy: 0.8857\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy (Dropout rate 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8761\n",
      "0.8761000037193298\n",
      "Accuracy: 87.61%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Model(Dropout rate 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training(Dropout rate 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.4242 - accuracy: 0.5076 - val_loss: 0.8076 - val_accuracy: 0.7228\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.8997 - accuracy: 0.6822 - val_loss: 0.6741 - val_accuracy: 0.7624\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7752 - accuracy: 0.7298 - val_loss: 0.6133 - val_accuracy: 0.7813\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7042 - accuracy: 0.7534 - val_loss: 0.5728 - val_accuracy: 0.7987\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6601 - accuracy: 0.7723 - val_loss: 0.5393 - val_accuracy: 0.8112\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6249 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.8192\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5964 - accuracy: 0.7900 - val_loss: 0.5002 - val_accuracy: 0.8245\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5759 - accuracy: 0.8000 - val_loss: 0.4854 - val_accuracy: 0.8302\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5583 - accuracy: 0.8062 - val_loss: 0.4757 - val_accuracy: 0.8299\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5437 - accuracy: 0.8105 - val_loss: 0.4640 - val_accuracy: 0.8348\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5299 - accuracy: 0.8142 - val_loss: 0.4564 - val_accuracy: 0.8380\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5163 - accuracy: 0.8195 - val_loss: 0.4477 - val_accuracy: 0.8401\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5105 - accuracy: 0.8211 - val_loss: 0.4412 - val_accuracy: 0.8417\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4991 - accuracy: 0.8248 - val_loss: 0.4335 - val_accuracy: 0.8449\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4900 - accuracy: 0.8282 - val_loss: 0.4258 - val_accuracy: 0.8468\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4814 - accuracy: 0.8301 - val_loss: 0.4233 - val_accuracy: 0.8498\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4737 - accuracy: 0.8343 - val_loss: 0.4174 - val_accuracy: 0.8500\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4675 - accuracy: 0.8360 - val_loss: 0.4137 - val_accuracy: 0.8520\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4652 - accuracy: 0.8365 - val_loss: 0.4076 - val_accuracy: 0.8542\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4619 - accuracy: 0.8359 - val_loss: 0.4032 - val_accuracy: 0.8549\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4528 - accuracy: 0.8404 - val_loss: 0.4023 - val_accuracy: 0.8556\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4486 - accuracy: 0.8409 - val_loss: 0.3989 - val_accuracy: 0.8563\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4429 - accuracy: 0.8441 - val_loss: 0.3963 - val_accuracy: 0.8579\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4391 - accuracy: 0.8439 - val_loss: 0.3905 - val_accuracy: 0.8586\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4359 - accuracy: 0.8459 - val_loss: 0.3876 - val_accuracy: 0.8602\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4302 - accuracy: 0.8481 - val_loss: 0.3853 - val_accuracy: 0.8626\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4239 - accuracy: 0.8487 - val_loss: 0.3825 - val_accuracy: 0.8622\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4239 - accuracy: 0.8509 - val_loss: 0.3812 - val_accuracy: 0.8636\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4199 - accuracy: 0.8510 - val_loss: 0.3770 - val_accuracy: 0.8644\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4162 - accuracy: 0.8521 - val_loss: 0.3779 - val_accuracy: 0.8623\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4120 - accuracy: 0.8541 - val_loss: 0.3728 - val_accuracy: 0.8648\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4103 - accuracy: 0.8546 - val_loss: 0.3736 - val_accuracy: 0.8651\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4076 - accuracy: 0.8537 - val_loss: 0.3705 - val_accuracy: 0.8668\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4042 - accuracy: 0.8564 - val_loss: 0.3686 - val_accuracy: 0.8670\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4018 - accuracy: 0.8580 - val_loss: 0.3674 - val_accuracy: 0.8683\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4005 - accuracy: 0.8584 - val_loss: 0.3628 - val_accuracy: 0.8692\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3965 - accuracy: 0.8580 - val_loss: 0.3625 - val_accuracy: 0.8693\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3923 - accuracy: 0.8605 - val_loss: 0.3596 - val_accuracy: 0.8699\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3915 - accuracy: 0.8608 - val_loss: 0.3593 - val_accuracy: 0.8713\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3897 - accuracy: 0.8622 - val_loss: 0.3578 - val_accuracy: 0.8716\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3851 - accuracy: 0.8644 - val_loss: 0.3581 - val_accuracy: 0.8708\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3826 - accuracy: 0.8654 - val_loss: 0.3544 - val_accuracy: 0.8722\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3827 - accuracy: 0.8648 - val_loss: 0.3529 - val_accuracy: 0.8726\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3828 - accuracy: 0.8642 - val_loss: 0.3508 - val_accuracy: 0.8737\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3777 - accuracy: 0.8656 - val_loss: 0.3496 - val_accuracy: 0.8749\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3747 - accuracy: 0.8670 - val_loss: 0.3484 - val_accuracy: 0.8749\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3739 - accuracy: 0.8657 - val_loss: 0.3487 - val_accuracy: 0.8749\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3708 - accuracy: 0.8666 - val_loss: 0.3463 - val_accuracy: 0.8755\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3726 - accuracy: 0.8675 - val_loss: 0.3450 - val_accuracy: 0.8761\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3691 - accuracy: 0.8696 - val_loss: 0.3467 - val_accuracy: 0.8760\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3658 - accuracy: 0.8696 - val_loss: 0.3420 - val_accuracy: 0.8769\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3665 - accuracy: 0.8703 - val_loss: 0.3418 - val_accuracy: 0.8763\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3603 - accuracy: 0.8706 - val_loss: 0.3404 - val_accuracy: 0.8761\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3582 - accuracy: 0.8720 - val_loss: 0.3401 - val_accuracy: 0.8764\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3586 - accuracy: 0.8720 - val_loss: 0.3394 - val_accuracy: 0.8765\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3572 - accuracy: 0.8733 - val_loss: 0.3376 - val_accuracy: 0.8771\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3548 - accuracy: 0.8750 - val_loss: 0.3365 - val_accuracy: 0.8778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3546 - accuracy: 0.8721 - val_loss: 0.3351 - val_accuracy: 0.8791\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3548 - accuracy: 0.8731 - val_loss: 0.3349 - val_accuracy: 0.8788\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3507 - accuracy: 0.8748 - val_loss: 0.3335 - val_accuracy: 0.8804\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy (Dropout rate 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8705\n",
      "0.8705000281333923\n",
      "Accuracy: 87.05%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Model(Dropout rate 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training(Dropout rate 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.9693 - accuracy: 0.3015 - val_loss: 1.2125 - val_accuracy: 0.6725\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.3743 - accuracy: 0.4982 - val_loss: 0.8933 - val_accuracy: 0.7011\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.1484 - accuracy: 0.5744 - val_loss: 0.7834 - val_accuracy: 0.7157\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.0305 - accuracy: 0.6170 - val_loss: 0.7300 - val_accuracy: 0.7332\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.9517 - accuracy: 0.6445 - val_loss: 0.6862 - val_accuracy: 0.7524\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.9004 - accuracy: 0.6657 - val_loss: 0.6617 - val_accuracy: 0.7577\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.8543 - accuracy: 0.6824 - val_loss: 0.6346 - val_accuracy: 0.7670\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.8258 - accuracy: 0.6963 - val_loss: 0.6148 - val_accuracy: 0.7752\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.8019 - accuracy: 0.7042 - val_loss: 0.5986 - val_accuracy: 0.7896\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7725 - accuracy: 0.7166 - val_loss: 0.5845 - val_accuracy: 0.7945\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7533 - accuracy: 0.7255 - val_loss: 0.5699 - val_accuracy: 0.8023\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7278 - accuracy: 0.7337 - val_loss: 0.5546 - val_accuracy: 0.8059\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7190 - accuracy: 0.7396 - val_loss: 0.5446 - val_accuracy: 0.8095\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7012 - accuracy: 0.7455 - val_loss: 0.5371 - val_accuracy: 0.8137\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6878 - accuracy: 0.7537 - val_loss: 0.5270 - val_accuracy: 0.8201\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6775 - accuracy: 0.7584 - val_loss: 0.5192 - val_accuracy: 0.8207\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6664 - accuracy: 0.7603 - val_loss: 0.5118 - val_accuracy: 0.8221\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6524 - accuracy: 0.7659 - val_loss: 0.5042 - val_accuracy: 0.8247\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6450 - accuracy: 0.7691 - val_loss: 0.4960 - val_accuracy: 0.8261\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6395 - accuracy: 0.7741 - val_loss: 0.4926 - val_accuracy: 0.8292\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6272 - accuracy: 0.7788 - val_loss: 0.4862 - val_accuracy: 0.8267\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6214 - accuracy: 0.7797 - val_loss: 0.4834 - val_accuracy: 0.8319\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6151 - accuracy: 0.7832 - val_loss: 0.4760 - val_accuracy: 0.8330\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6042 - accuracy: 0.7879 - val_loss: 0.4723 - val_accuracy: 0.8337\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5997 - accuracy: 0.7887 - val_loss: 0.4695 - val_accuracy: 0.8333\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5910 - accuracy: 0.7924 - val_loss: 0.4627 - val_accuracy: 0.8359\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5865 - accuracy: 0.7952 - val_loss: 0.4601 - val_accuracy: 0.8348\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5828 - accuracy: 0.7950 - val_loss: 0.4626 - val_accuracy: 0.8357\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5780 - accuracy: 0.7985 - val_loss: 0.4522 - val_accuracy: 0.8394\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5800 - accuracy: 0.7984 - val_loss: 0.4520 - val_accuracy: 0.8393\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5697 - accuracy: 0.8010 - val_loss: 0.4480 - val_accuracy: 0.8389\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5638 - accuracy: 0.8043 - val_loss: 0.4447 - val_accuracy: 0.8417\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5611 - accuracy: 0.8027 - val_loss: 0.4429 - val_accuracy: 0.8413\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5567 - accuracy: 0.8042 - val_loss: 0.4397 - val_accuracy: 0.8428\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5487 - accuracy: 0.8078 - val_loss: 0.4387 - val_accuracy: 0.8432\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5543 - accuracy: 0.8069 - val_loss: 0.4355 - val_accuracy: 0.8441\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5479 - accuracy: 0.8086 - val_loss: 0.4330 - val_accuracy: 0.8448\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5462 - accuracy: 0.8105 - val_loss: 0.4320 - val_accuracy: 0.8448\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5412 - accuracy: 0.8117 - val_loss: 0.4317 - val_accuracy: 0.8444\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5432 - accuracy: 0.8113 - val_loss: 0.4287 - val_accuracy: 0.8461\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5348 - accuracy: 0.8147 - val_loss: 0.4257 - val_accuracy: 0.8482\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5291 - accuracy: 0.8143 - val_loss: 0.4240 - val_accuracy: 0.8478\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5288 - accuracy: 0.8149 - val_loss: 0.4218 - val_accuracy: 0.8501\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5242 - accuracy: 0.8190 - val_loss: 0.4197 - val_accuracy: 0.8509\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5228 - accuracy: 0.8186 - val_loss: 0.4188 - val_accuracy: 0.8503\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5200 - accuracy: 0.8199 - val_loss: 0.4187 - val_accuracy: 0.8508\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5183 - accuracy: 0.8197 - val_loss: 0.4156 - val_accuracy: 0.8518\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5131 - accuracy: 0.8204 - val_loss: 0.4143 - val_accuracy: 0.8527\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5135 - accuracy: 0.8229 - val_loss: 0.4125 - val_accuracy: 0.8541\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5079 - accuracy: 0.8233 - val_loss: 0.4108 - val_accuracy: 0.8537\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5088 - accuracy: 0.8231 - val_loss: 0.4105 - val_accuracy: 0.8522\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5085 - accuracy: 0.8237 - val_loss: 0.4099 - val_accuracy: 0.8540\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5063 - accuracy: 0.8246 - val_loss: 0.4108 - val_accuracy: 0.8521\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5027 - accuracy: 0.8247 - val_loss: 0.4071 - val_accuracy: 0.8551\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5011 - accuracy: 0.8255 - val_loss: 0.4074 - val_accuracy: 0.8546\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4941 - accuracy: 0.8301 - val_loss: 0.4056 - val_accuracy: 0.8557\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4922 - accuracy: 0.8287 - val_loss: 0.4018 - val_accuracy: 0.8561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4956 - accuracy: 0.8272 - val_loss: 0.4024 - val_accuracy: 0.8571\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4938 - accuracy: 0.8285 - val_loss: 0.4011 - val_accuracy: 0.8577\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4877 - accuracy: 0.8315 - val_loss: 0.3991 - val_accuracy: 0.8590\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy (Dropout rate 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8513\n",
      "0.8513000011444092\n",
      "Accuracy: 85.13%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout rate의 변화와 그에 따른 Accuracy 비교\n",
    "\n",
    "위의 세 경우에 대해, Dropout rate가 각각 0.2,0.5,0.8 일때, 87.61%, 87.05%, 85.13%로 점점 감소한다. 이렇게 변하는 이유는 무엇일까? 기본적으로 Dropout은 DNN에서 각 layer의 노드들이 각각 맡고 있는 입력들에 대해 더욱 잘 분석하도록 하기 위해 사용하는데, 뉴런이 다른 뉴런에 의존하는 co-adaptation문제를 해결하고 overfitting 문제를 개선하는 효과를 가지고 있다. 하지만 이 dropout은 학습 시 임의로 쳐내는 그 비율에 따라 성능이 크게 달라질 수 있는데, 위 3가지 케이스의 정확도를 보면 이게 잘 드러난다. \n",
    "0.2의 dropout rate을 적용한 것의 train 결과를 보면 validation loss가 epoch을 거듭할수록 감소하며, 다시 증가하지는 않는다. 이는 overfitting 문제가 그렇게 드러나지 않은 결과이고, 다시 말하면 10개 중 2개의 노드만 0으로 설정하여 학습시켰는데도 이미 원하는 모델에 가까워졌음을 뜻한다. 여기서 더 많은 입력노드를 쳐내버린 0.5와 0.8은, 물론 그 정확도가 급격하게 떨어질 정도는 아니지만, epoch을 60회나 수행했음에도 학습 과정에서 너무 많은 입력 노드를 무시한 결과 충분한 학습이 되지 못해 정확도가 떨어지는 양상을 보인다. 즉 무조건 많이 dropout을 진행하는 것이 아니라 적절한 비율을 찾아 그를 적용해야 올바른 학습이 진행되고, 이런 결과는 batch normalization을 진행한 아래 케이스들에서도 똑같은 양상으로 나타난다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define Model(Dropout rate 0.2 + Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training(Dropout rate 0.2 + Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.7265 - accuracy: 0.7486 - val_loss: 0.4972 - val_accuracy: 0.8322\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5088 - accuracy: 0.8180 - val_loss: 0.4100 - val_accuracy: 0.8505\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4582 - accuracy: 0.8368 - val_loss: 0.3880 - val_accuracy: 0.8613\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4270 - accuracy: 0.8475 - val_loss: 0.3732 - val_accuracy: 0.8644\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4029 - accuracy: 0.8552 - val_loss: 0.3591 - val_accuracy: 0.8701\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3843 - accuracy: 0.8613 - val_loss: 0.3528 - val_accuracy: 0.8724\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3709 - accuracy: 0.8664 - val_loss: 0.3448 - val_accuracy: 0.8762\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3589 - accuracy: 0.8711 - val_loss: 0.3380 - val_accuracy: 0.8773\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3464 - accuracy: 0.8739 - val_loss: 0.3385 - val_accuracy: 0.8770\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3393 - accuracy: 0.8781 - val_loss: 0.3296 - val_accuracy: 0.8817\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3296 - accuracy: 0.8794 - val_loss: 0.3301 - val_accuracy: 0.8812\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3217 - accuracy: 0.8825 - val_loss: 0.3197 - val_accuracy: 0.8853\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3123 - accuracy: 0.8855 - val_loss: 0.3254 - val_accuracy: 0.8808\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3069 - accuracy: 0.8890 - val_loss: 0.3175 - val_accuracy: 0.8872\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3000 - accuracy: 0.8903 - val_loss: 0.3178 - val_accuracy: 0.8845\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2949 - accuracy: 0.8907 - val_loss: 0.3149 - val_accuracy: 0.8856\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2895 - accuracy: 0.8935 - val_loss: 0.3137 - val_accuracy: 0.8855\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2828 - accuracy: 0.8953 - val_loss: 0.3145 - val_accuracy: 0.8860\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2802 - accuracy: 0.8969 - val_loss: 0.3079 - val_accuracy: 0.8892\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2726 - accuracy: 0.9008 - val_loss: 0.3108 - val_accuracy: 0.8878\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2668 - accuracy: 0.9021 - val_loss: 0.3092 - val_accuracy: 0.8891\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2643 - accuracy: 0.9036 - val_loss: 0.3160 - val_accuracy: 0.8864\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2607 - accuracy: 0.9043 - val_loss: 0.3126 - val_accuracy: 0.8888\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2530 - accuracy: 0.9065 - val_loss: 0.3036 - val_accuracy: 0.8909\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2527 - accuracy: 0.9067 - val_loss: 0.3093 - val_accuracy: 0.8889\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2469 - accuracy: 0.9089 - val_loss: 0.3038 - val_accuracy: 0.8909\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2433 - accuracy: 0.9099 - val_loss: 0.3090 - val_accuracy: 0.8913\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2401 - accuracy: 0.9110 - val_loss: 0.3044 - val_accuracy: 0.8907\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2367 - accuracy: 0.9116 - val_loss: 0.3053 - val_accuracy: 0.8914\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2302 - accuracy: 0.9147 - val_loss: 0.3020 - val_accuracy: 0.8905\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2291 - accuracy: 0.9150 - val_loss: 0.3036 - val_accuracy: 0.8923\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2254 - accuracy: 0.9154 - val_loss: 0.3042 - val_accuracy: 0.8918\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2232 - accuracy: 0.9181 - val_loss: 0.3024 - val_accuracy: 0.8910\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2170 - accuracy: 0.9202 - val_loss: 0.3065 - val_accuracy: 0.8911\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2149 - accuracy: 0.9208 - val_loss: 0.3051 - val_accuracy: 0.8917\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2117 - accuracy: 0.9214 - val_loss: 0.2992 - val_accuracy: 0.8933\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2115 - accuracy: 0.9223 - val_loss: 0.3019 - val_accuracy: 0.8933\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2070 - accuracy: 0.9237 - val_loss: 0.3059 - val_accuracy: 0.8905\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2031 - accuracy: 0.9253 - val_loss: 0.3022 - val_accuracy: 0.8935\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2006 - accuracy: 0.9257 - val_loss: 0.3072 - val_accuracy: 0.8933\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1981 - accuracy: 0.9265 - val_loss: 0.3064 - val_accuracy: 0.8927\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1938 - accuracy: 0.9268 - val_loss: 0.3113 - val_accuracy: 0.8912\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1943 - accuracy: 0.9285 - val_loss: 0.3077 - val_accuracy: 0.8939\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1906 - accuracy: 0.9299 - val_loss: 0.3110 - val_accuracy: 0.8903\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1875 - accuracy: 0.9313 - val_loss: 0.3133 - val_accuracy: 0.8913\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1841 - accuracy: 0.9309 - val_loss: 0.3103 - val_accuracy: 0.8939\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1794 - accuracy: 0.9333 - val_loss: 0.3057 - val_accuracy: 0.8949\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1801 - accuracy: 0.9322 - val_loss: 0.3175 - val_accuracy: 0.8913\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1760 - accuracy: 0.9346 - val_loss: 0.3111 - val_accuracy: 0.8920\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1781 - accuracy: 0.9338 - val_loss: 0.3125 - val_accuracy: 0.8924\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1730 - accuracy: 0.9347 - val_loss: 0.3060 - val_accuracy: 0.8965\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1734 - accuracy: 0.9352 - val_loss: 0.3077 - val_accuracy: 0.8955\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1686 - accuracy: 0.9384 - val_loss: 0.3204 - val_accuracy: 0.8907\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1644 - accuracy: 0.9395 - val_loss: 0.3119 - val_accuracy: 0.8938\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1647 - accuracy: 0.9397 - val_loss: 0.3161 - val_accuracy: 0.8951\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1601 - accuracy: 0.9409 - val_loss: 0.3129 - val_accuracy: 0.8959\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1579 - accuracy: 0.9416 - val_loss: 0.3141 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1569 - accuracy: 0.9421 - val_loss: 0.3122 - val_accuracy: 0.8967\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1553 - accuracy: 0.9427 - val_loss: 0.3165 - val_accuracy: 0.8919\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1527 - accuracy: 0.9428 - val_loss: 0.3201 - val_accuracy: 0.8921\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy (Dropout rate 0.2 + Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8900\n",
      "0.8899999856948853\n",
      "Accuracy: 89.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Define Model(Dropout rate 0.5 + Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training(Dropout rate 0.5 + Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 1.0515 - accuracy: 0.6438 - val_loss: 0.5981 - val_accuracy: 0.7930\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6882 - accuracy: 0.7562 - val_loss: 0.4860 - val_accuracy: 0.8262\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6095 - accuracy: 0.7858 - val_loss: 0.4523 - val_accuracy: 0.8369\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5656 - accuracy: 0.7996 - val_loss: 0.4381 - val_accuracy: 0.8397\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5365 - accuracy: 0.8107 - val_loss: 0.4193 - val_accuracy: 0.8486\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5138 - accuracy: 0.8171 - val_loss: 0.4090 - val_accuracy: 0.8518\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4965 - accuracy: 0.8219 - val_loss: 0.4047 - val_accuracy: 0.8520\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4830 - accuracy: 0.8285 - val_loss: 0.3989 - val_accuracy: 0.8551\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4648 - accuracy: 0.8326 - val_loss: 0.3864 - val_accuracy: 0.8578\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4551 - accuracy: 0.8369 - val_loss: 0.3818 - val_accuracy: 0.8600\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4459 - accuracy: 0.8391 - val_loss: 0.3778 - val_accuracy: 0.8644\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4334 - accuracy: 0.8456 - val_loss: 0.3720 - val_accuracy: 0.8661\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4272 - accuracy: 0.8462 - val_loss: 0.3659 - val_accuracy: 0.8665\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4218 - accuracy: 0.8483 - val_loss: 0.3701 - val_accuracy: 0.8653\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4187 - accuracy: 0.8491 - val_loss: 0.3618 - val_accuracy: 0.8681\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4129 - accuracy: 0.8505 - val_loss: 0.3614 - val_accuracy: 0.8684\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4063 - accuracy: 0.8519 - val_loss: 0.3518 - val_accuracy: 0.8730\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3990 - accuracy: 0.8565 - val_loss: 0.3555 - val_accuracy: 0.8706\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3929 - accuracy: 0.8581 - val_loss: 0.3498 - val_accuracy: 0.8737\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3906 - accuracy: 0.8593 - val_loss: 0.3497 - val_accuracy: 0.8736\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3846 - accuracy: 0.8613 - val_loss: 0.3454 - val_accuracy: 0.8763\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3812 - accuracy: 0.8619 - val_loss: 0.3518 - val_accuracy: 0.8726\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3775 - accuracy: 0.8639 - val_loss: 0.3402 - val_accuracy: 0.8779\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3719 - accuracy: 0.8667 - val_loss: 0.3414 - val_accuracy: 0.8744\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3705 - accuracy: 0.8665 - val_loss: 0.3395 - val_accuracy: 0.8777\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3696 - accuracy: 0.8663 - val_loss: 0.3359 - val_accuracy: 0.8799\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3652 - accuracy: 0.8687 - val_loss: 0.3336 - val_accuracy: 0.8802\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3600 - accuracy: 0.8717 - val_loss: 0.3346 - val_accuracy: 0.8782\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3595 - accuracy: 0.8702 - val_loss: 0.3329 - val_accuracy: 0.8795\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3567 - accuracy: 0.8708 - val_loss: 0.3322 - val_accuracy: 0.8783\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3514 - accuracy: 0.8716 - val_loss: 0.3284 - val_accuracy: 0.8808\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3465 - accuracy: 0.8765 - val_loss: 0.3294 - val_accuracy: 0.8811\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3483 - accuracy: 0.8745 - val_loss: 0.3266 - val_accuracy: 0.8827\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3428 - accuracy: 0.8781 - val_loss: 0.3233 - val_accuracy: 0.8829\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3434 - accuracy: 0.8740 - val_loss: 0.3275 - val_accuracy: 0.8831\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3386 - accuracy: 0.8771 - val_loss: 0.3202 - val_accuracy: 0.8842\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3345 - accuracy: 0.8762 - val_loss: 0.3222 - val_accuracy: 0.8832\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3356 - accuracy: 0.8789 - val_loss: 0.3161 - val_accuracy: 0.8829\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3303 - accuracy: 0.8794 - val_loss: 0.3263 - val_accuracy: 0.8829\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3267 - accuracy: 0.8791 - val_loss: 0.3211 - val_accuracy: 0.8840\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3271 - accuracy: 0.8814 - val_loss: 0.3137 - val_accuracy: 0.8864\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3226 - accuracy: 0.8831 - val_loss: 0.3164 - val_accuracy: 0.8852\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3211 - accuracy: 0.8839 - val_loss: 0.3131 - val_accuracy: 0.8854\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3228 - accuracy: 0.8830 - val_loss: 0.3138 - val_accuracy: 0.8852\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3162 - accuracy: 0.8846 - val_loss: 0.3171 - val_accuracy: 0.8869\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3151 - accuracy: 0.8862 - val_loss: 0.3115 - val_accuracy: 0.8870\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3120 - accuracy: 0.8865 - val_loss: 0.3153 - val_accuracy: 0.8860\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3144 - accuracy: 0.8856 - val_loss: 0.3143 - val_accuracy: 0.8857\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3092 - accuracy: 0.8868 - val_loss: 0.3104 - val_accuracy: 0.8885\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3082 - accuracy: 0.8881 - val_loss: 0.3154 - val_accuracy: 0.8867\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3062 - accuracy: 0.8874 - val_loss: 0.3107 - val_accuracy: 0.8867\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3080 - accuracy: 0.8863 - val_loss: 0.3096 - val_accuracy: 0.8879\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3017 - accuracy: 0.8892 - val_loss: 0.3163 - val_accuracy: 0.8862\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3012 - accuracy: 0.8899 - val_loss: 0.3061 - val_accuracy: 0.8888\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.2989 - accuracy: 0.8899 - val_loss: 0.3079 - val_accuracy: 0.8892\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2994 - accuracy: 0.8908 - val_loss: 0.3096 - val_accuracy: 0.8881\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2975 - accuracy: 0.8912 - val_loss: 0.3044 - val_accuracy: 0.8882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.2933 - accuracy: 0.8914 - val_loss: 0.3055 - val_accuracy: 0.8896\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2903 - accuracy: 0.8912 - val_loss: 0.3083 - val_accuracy: 0.8870\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2912 - accuracy: 0.8924 - val_loss: 0.3072 - val_accuracy: 0.8894\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy (Dropout rate 0.5 + Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8830\n",
      "0.8830000162124634\n",
      "Accuracy: 88.30%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Define Model(Dropout rate 0.8 + Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training(Dropout rate 0.8 + Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 2.0291 - accuracy: 0.3167 - val_loss: 1.0188 - val_accuracy: 0.6898\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 1.3123 - accuracy: 0.5219 - val_loss: 0.7959 - val_accuracy: 0.7172\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 1.0915 - accuracy: 0.5982 - val_loss: 0.7228 - val_accuracy: 0.7317\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.9776 - accuracy: 0.6412 - val_loss: 0.6802 - val_accuracy: 0.7469\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.9086 - accuracy: 0.6652 - val_loss: 0.6533 - val_accuracy: 0.7588\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.8663 - accuracy: 0.6795 - val_loss: 0.6262 - val_accuracy: 0.7741\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.8334 - accuracy: 0.6936 - val_loss: 0.6068 - val_accuracy: 0.7819\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.7933 - accuracy: 0.7110 - val_loss: 0.5940 - val_accuracy: 0.7880\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.7747 - accuracy: 0.7193 - val_loss: 0.5812 - val_accuracy: 0.7919\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.7490 - accuracy: 0.7289 - val_loss: 0.5668 - val_accuracy: 0.7978\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.7315 - accuracy: 0.7366 - val_loss: 0.5580 - val_accuracy: 0.8006\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.7138 - accuracy: 0.7436 - val_loss: 0.5445 - val_accuracy: 0.8064\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.7071 - accuracy: 0.7483 - val_loss: 0.5312 - val_accuracy: 0.8117\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6916 - accuracy: 0.7527 - val_loss: 0.5296 - val_accuracy: 0.8125\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6777 - accuracy: 0.7578 - val_loss: 0.5263 - val_accuracy: 0.8116\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6708 - accuracy: 0.7620 - val_loss: 0.5143 - val_accuracy: 0.8191\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6640 - accuracy: 0.7637 - val_loss: 0.5125 - val_accuracy: 0.8194\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6530 - accuracy: 0.7676 - val_loss: 0.4980 - val_accuracy: 0.8229\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6404 - accuracy: 0.7739 - val_loss: 0.4966 - val_accuracy: 0.8237\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6326 - accuracy: 0.7757 - val_loss: 0.4929 - val_accuracy: 0.8253\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6300 - accuracy: 0.7768 - val_loss: 0.4860 - val_accuracy: 0.8288\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6197 - accuracy: 0.7819 - val_loss: 0.4847 - val_accuracy: 0.8278\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6178 - accuracy: 0.7830 - val_loss: 0.4755 - val_accuracy: 0.8324\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6090 - accuracy: 0.7859 - val_loss: 0.4769 - val_accuracy: 0.8312\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6060 - accuracy: 0.7848 - val_loss: 0.4708 - val_accuracy: 0.8346\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5989 - accuracy: 0.7901 - val_loss: 0.4646 - val_accuracy: 0.8360\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5905 - accuracy: 0.7933 - val_loss: 0.4627 - val_accuracy: 0.8345\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5891 - accuracy: 0.7929 - val_loss: 0.4604 - val_accuracy: 0.8365\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5850 - accuracy: 0.7941 - val_loss: 0.4556 - val_accuracy: 0.8408\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5824 - accuracy: 0.7946 - val_loss: 0.4529 - val_accuracy: 0.8397\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5755 - accuracy: 0.7980 - val_loss: 0.4471 - val_accuracy: 0.8401\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5710 - accuracy: 0.7979 - val_loss: 0.4461 - val_accuracy: 0.8422\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5726 - accuracy: 0.7995 - val_loss: 0.4449 - val_accuracy: 0.8422\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5660 - accuracy: 0.8011 - val_loss: 0.4423 - val_accuracy: 0.8442\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5571 - accuracy: 0.8048 - val_loss: 0.4416 - val_accuracy: 0.8447\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5572 - accuracy: 0.8033 - val_loss: 0.4345 - val_accuracy: 0.8461\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5545 - accuracy: 0.8064 - val_loss: 0.4356 - val_accuracy: 0.8478\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5560 - accuracy: 0.8052 - val_loss: 0.4365 - val_accuracy: 0.8469\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5486 - accuracy: 0.8076 - val_loss: 0.4342 - val_accuracy: 0.8473\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5448 - accuracy: 0.8107 - val_loss: 0.4330 - val_accuracy: 0.8478\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5449 - accuracy: 0.8090 - val_loss: 0.4320 - val_accuracy: 0.8495\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5414 - accuracy: 0.8113 - val_loss: 0.4262 - val_accuracy: 0.8498\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5403 - accuracy: 0.8124 - val_loss: 0.4268 - val_accuracy: 0.8503\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5356 - accuracy: 0.8145 - val_loss: 0.4268 - val_accuracy: 0.8509\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5303 - accuracy: 0.8152 - val_loss: 0.4255 - val_accuracy: 0.8481\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5310 - accuracy: 0.8154 - val_loss: 0.4200 - val_accuracy: 0.8514\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5303 - accuracy: 0.8153 - val_loss: 0.4168 - val_accuracy: 0.8533\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.5298 - accuracy: 0.8136 - val_loss: 0.4237 - val_accuracy: 0.8505\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5228 - accuracy: 0.8178 - val_loss: 0.4158 - val_accuracy: 0.8537\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5185 - accuracy: 0.8177 - val_loss: 0.4169 - val_accuracy: 0.8528\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.5228 - accuracy: 0.8160 - val_loss: 0.4158 - val_accuracy: 0.8537\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5192 - accuracy: 0.8173 - val_loss: 0.4146 - val_accuracy: 0.8533\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5167 - accuracy: 0.8193 - val_loss: 0.4133 - val_accuracy: 0.8522\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5095 - accuracy: 0.8215 - val_loss: 0.4113 - val_accuracy: 0.8547\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5082 - accuracy: 0.8223 - val_loss: 0.4101 - val_accuracy: 0.8558\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5088 - accuracy: 0.8225 - val_loss: 0.4106 - val_accuracy: 0.8556\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5074 - accuracy: 0.8212 - val_loss: 0.4075 - val_accuracy: 0.8555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5035 - accuracy: 0.8246 - val_loss: 0.4063 - val_accuracy: 0.8583\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5082 - accuracy: 0.8222 - val_loss: 0.4044 - val_accuracy: 0.8561\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5043 - accuracy: 0.8248 - val_loss: 0.4056 - val_accuracy: 0.8597\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy (Dropout rate 0.8 + Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4258 - accuracy: 0.8496\n",
      "0.8496000170707703\n",
      "Accuracy: 84.96%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization을 Dropout과 함께 적용한 모델 vs \n",
    "# Dropout만 진행했을 때의 정확도 비교\n",
    "\n",
    "\n",
    "위에서 확인할 수 있다시피 0.8의 dropout rate일때는 비슷한 정확도였지만, 0.2 와 0.5 의 dropout rate가 적용되었을 때는 확연히 batch normalization을 함께 진행했을 때가 정확도가 높았다. 1~3번 케이스에서 살펴본 바를 적용하면 적절한 dropout rate라고 할 수 있는 0.2의 경우를 볼 때 결국 Batch Normalization이 DNN 학습에 긍정적인 영향을 주었다고 볼 수 있을 것이다.(사실 batch normalization은 그 자체로 dropout의 필요성을 감소시키는 영향도 존재한다.)\n",
    "그 이유는 무엇인가? Batch Normalization이라는 것은, 앞에서 vanishing gradient같은 문제를 해결하기 위해 activation 함수를 조절하는 간접적인 방법을 사용한 것과 더불어,학습 과정 자체에 그 input data를 적절히 조절해 학습을 원활하게 만드는 방법이다. 학습 과정에서 dimension별로 정규화한 결과 학습 속도가 빨라지고 초기값에 의존하는 정도를 감소시키는 역할을 한다. 무엇보다 gradient flow가 batch normalization을 적용함으로써 더 개선되어 학습 성능이 향상되고, 그 결과가 나타난 것이라고 보면 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
